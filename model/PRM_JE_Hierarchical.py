# PRM_JE_Hierarchical.py - åˆ†å±‚ç‰ˆæœ¬çš„PRM_JE
# åŸºäºåŸPRM_JE.pyä¿®æ”¹ï¼Œæ–°å¢åˆ†å±‚å¼ºåŒ–å­¦ä¹ åŠŸèƒ½

from typing import List, Optional, Tuple, Dict
import torch
import torch.nn.functional as F
from torch import nn
import os
import math
import numpy as np


# ============================================================================
# åŸºç¡€ç»„ä»¶å®šä¹‰
# ============================================================================

# SEæ³¨æ„åŠ›æ¨¡å—
class SEBlock(nn.Module):
    """Squeeze-and-Excitation Block"""

    def __init__(self, channels, reduction=16):
        super().__init__()
        self.squeeze = nn.AdaptiveAvgPool2d(1)
        self.excitation = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c = x.size(0), x.size(1)
        y = self.squeeze(x).view(b, c)
        y = self.excitation(y).view(b, c, 1, 1)
        return x * y


# å¢å¼ºæ®‹å·®å—
class EnhancedResidualBlock(nn.Module):
    """å¢å¼ºçš„æ®‹å·®å—ï¼ŒåŒ…å«SEæ³¨æ„åŠ›"""

    def __init__(self, channels, num_layers=2, use_se=True):
        super().__init__()
        self.use_se = use_se

        layers = []
        for i in range(num_layers):
            layers.extend([
                nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False),
                nn.BatchNorm2d(channels),
            ])
            if i < num_layers - 1:
                layers.append(nn.ReLU(inplace=True))

        self.conv_layers = nn.Sequential(*layers)

        if self.use_se:
            self.se = SEBlock(channels)

        self.final_relu = nn.ReLU(inplace=True)

    def forward(self, x):
        identity = x
        out = self.conv_layers(x)

        if self.use_se:
            out = self.se(out)

        out = out + identity
        out = self.final_relu(out)
        return out


class DownBlock2d(nn.Module):
    """ä¸‹é‡‡æ ·å—"""

    def __init__(self, in_channels, out_channels, num_layers, downsample=False, use_se=True):
        super().__init__()
        self.downsample = downsample
        stride = 2 if downsample else 1

        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)

        self.residual_blocks = nn.ModuleList([
            EnhancedResidualBlock(out_channels, 2, use_se) for _ in range(num_layers)
        ])

        self.shortcut = nn.Identity()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        identity = self.shortcut(x)
        out = self.conv(x)
        out = self.bn(out)
        out = self.relu(out)

        if self.downsample and identity.shape[2:] != out.shape[2:]:
            identity = F.adaptive_avg_pool2d(identity, out.shape[2:])

        out = out + identity

        for res_block in self.residual_blocks:
            out = res_block(out)

        return out


# åŠ¨ä½œç¼–ç å™¨
class ActionEncoder(nn.Module):
    """åŠ¨ä½œç¼–ç å™¨ï¼Œå°†0-18çš„æ•´æ•°åŠ¨ä½œç¼–ç ä¸ºå‘é‡"""

    def __init__(self, action_dim=19, embed_dim=128, output_dim=256):
        super().__init__()
        self.action_embedding = nn.Embedding(action_dim, embed_dim)
        self.action_proj = nn.Sequential(
            nn.Linear(embed_dim, output_dim),
            nn.LayerNorm(output_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1)
        )

    def forward(self, actions):
        embedded = self.action_embedding(actions.long())
        return self.action_proj(embedded)


# ç¼–ç å™¨
class Encoder(nn.Module):
    """ç¼–ç å™¨ï¼Œè¾“å…¥210*160*3 å›¾åƒ"""

    def __init__(self, in_channels: int = 3, layers: List[int] = [2, 3, 4, 3], base_channels: int = 64) -> None:
        super().__init__()

        # Stemå±‚ - å¤„ç†210*160*3è¾“å…¥
        self.stem = nn.Sequential(
            nn.Conv2d(in_channels, base_channels // 2, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(base_channels // 2),
            nn.ReLU(inplace=True),
            nn.Conv2d(base_channels // 2, base_channels, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(base_channels),
            nn.ReLU(inplace=True),
        )

        # ç‰¹å¾æå–ç½‘ç»œ
        self.layer1 = DownBlock2d(base_channels, base_channels, layers[0], downsample=False)
        self.layer2 = DownBlock2d(base_channels, base_channels * 2, layers[1], downsample=True)
        self.layer3 = DownBlock2d(base_channels * 2, base_channels * 4, layers[2], downsample=True)
        self.layer4 = DownBlock2d(base_channels * 4, base_channels * 8, layers[3], downsample=True)

        # å…¨å±€å¹³å‡æ± åŒ–
        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))

        # ç‰¹å¾æŠ•å½±
        self.feature_proj = nn.Sequential(
            nn.Linear(base_channels * 8, 512),
            nn.LayerNorm(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(512, 256),
            nn.LayerNorm(256)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        assert x.shape[-2:] == (210, 160), f"Expected input size (210, 160), got {x.shape[-2:]}"

        x = self.stem(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        pooled = self.global_pool(x)
        flattened = pooled.view(pooled.size(0), -1)
        features = self.feature_proj(flattened)

        return features


# ============================================================================
# åˆ†å±‚å¼ºåŒ–å­¦ä¹ ç»„ä»¶
# ============================================================================

# ç›®æ ‡ç¼–ç å™¨
class GoalEncoder(nn.Module):
    """ç›®æ ‡ç¼–ç å™¨ - å°†ä¸åŒç±»å‹çš„ç›®æ ‡ç¼–ç ä¸ºç»Ÿä¸€å‘é‡
    """

    def __init__(self, goal_dim: int = 64, output_dim: int = 256):
        super().__init__()
        # goal_dim:ä¸­é—´éšè—å±‚ç»´åº¦,output_dim: æœ€ç»ˆç¼–ç è¾“å‡ºçš„ç»Ÿä¸€ç»´åº¦

        # ç©ºé—´ç›®æ ‡ç¼–ç å™¨ï¼ˆx, yåæ ‡ï¼‰
        self.spatial_encoder = nn.Sequential(
            nn.Linear(2, goal_dim),
            nn.ReLU(),
            nn.Linear(goal_dim, output_dim),
            nn.LayerNorm(output_dim)
        )

        # å¯¹è±¡ç›®æ ‡ç¼–ç å™¨ï¼ˆå¯¹è±¡IDï¼‰
        # å‡è®¾æœ€å¤š10ç§å¯¹è±¡
        self.object_encoder = nn.Sequential(
            nn.Embedding(10, goal_dim),
            nn.Linear(goal_dim, output_dim),
            nn.LayerNorm(output_dim)
        )

        # æ¢ç´¢ç›®æ ‡ç¼–ç å™¨ï¼ˆæ¢ç´¢æ–¹å‘ï¼‰
        self.exploration_encoder = nn.Sequential(
            nn.Linear(4, goal_dim),  # ä¸Šä¸‹å·¦å³å››ä¸ªæ–¹å‘
            nn.ReLU(),
            nn.Linear(goal_dim, output_dim),
            nn.LayerNorm(output_dim)
        )

    def forward(self, goal_type: str, goal_params: torch.Tensor) -> torch.Tensor:
        """
        Args:
            goal_type: ç›®æ ‡ç±»å‹ ('spatial', 'object', 'exploration')
            goal_params: ç›®æ ‡å‚æ•°
        Returns:
            goal_features: ç¼–ç åçš„ç›®æ ‡ç‰¹å¾ (B, output_dim)
        """
        if goal_type == 'spatial':
            return self.spatial_encoder(goal_params)
        elif goal_type == 'object':
            return self.object_encoder(goal_params.long().squeeze(-1))
        elif goal_type == 'exploration':
            return self.exploration_encoder(goal_params)
        else:
            raise ValueError(f"Unknown goal type: {goal_type}")


# å…ƒæ§åˆ¶å™¨
class MetaController(nn.Module):
    """å…ƒæ§åˆ¶å™¨ - è´Ÿè´£é€‰æ‹©é«˜çº§ç›®æ ‡
    é€šè¿‡Q-network è¯„ä¼°å„ç±»ç›®æ ‡çš„ä»·å€¼ï¼Œè¾“å‡º Q å€¼"""

    def __init__(self, state_dim: int = 256, hidden_dim: int = 512, num_goal_types: int = 3):
        super().__init__()

        # Qç½‘ç»œï¼šä¼°è®¡é€‰æ‹©ä¸åŒç›®æ ‡ç±»å‹çš„ä»·å€¼
        self.q_network = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, num_goal_types)
        )

        # ç›®æ ‡å‚æ•°ç”Ÿæˆå™¨
        self.goal_param_generators = nn.ModuleDict({
            'spatial': nn.Sequential(
                nn.Linear(state_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, 2),  # x, yåæ ‡
                nn.Tanh()  # å½’ä¸€åŒ–åˆ°[-1, 1]
            ),
            'object': nn.Sequential(
                nn.Linear(state_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, 1),  # å¯¹è±¡ID
                nn.Sigmoid()  # å½’ä¸€åŒ–åˆ°[0, 1]ï¼Œç„¶åå¯ä»¥ä¹˜ä»¥å¯¹è±¡æ•°é‡
            ),
            'exploration': nn.Sequential(
                nn.Linear(state_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, 4),  # å››ä¸ªæ–¹å‘çš„æƒé‡
                nn.Softmax(dim=-1)
            )
        })

        self.goal_types = ['spatial', 'object', 'exploration']

    def forward(self, state_features: torch.Tensor, goal_type: str = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            state_features: çŠ¶æ€ç‰¹å¾ (B, state_dim)
            goal_type: æŒ‡å®šçš„ç›®æ ‡ç±»å‹ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰ç±»å‹çš„Qå€¼
        Returns:
            goal_q_values: ç›®æ ‡é€‰æ‹©Qå€¼ (B, num_goal_types)
            goal_params: ç›®æ ‡å‚æ•° (B, param_dim) æˆ– None
        """
        # è®¡ç®—ç›®æ ‡é€‰æ‹©Qå€¼
        goal_q_values = self.q_network(state_features)

        if goal_type is not None:
            # ç”Ÿæˆç‰¹å®šç±»å‹ç›®æ ‡çš„å‚æ•°
            goal_params = self.goal_param_generators[goal_type](state_features)
            return goal_q_values, goal_params

        return goal_q_values, None


# å†…åœ¨å¥–åŠ±è®¡ç®—å™¨
class IntrinsicCritic(nn.Module):
    """
    å†…åœ¨å¥–åŠ±è®¡ç®—å™¨ - è¯„ä¼°ç›®æ ‡å®Œæˆæƒ…å†µ/æ¨¡å‹è‡ªå·±è¯„ä¼°å½“å‰åŠ¨ä½œå¯¹å®ç°é«˜å±‚ç›®æ ‡æœ‰å¤šå¤§å¸®åŠ©
    æ¥æ”¶å½“å‰çŠ¶æ€ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ï¼Œè¾“å‡ºä¸€ä¸ª 0 åˆ° 1 ä¹‹é—´çš„å€¼ï¼Œè¡¨ç¤ºå®Œæˆç›®æ ‡çš„è¿›å±•ã€‚å€¼è¶Šé«˜è¡¨ç¤ºè¿›å±•è¶Šå¥½
    """

    def __init__(self, state_dim: int = 256, goal_dim: int = 256):
        super().__init__()

        self.reward_network = nn.Sequential(
            nn.Linear(state_dim + goal_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 1),
            nn.Sigmoid()  # è¾“å‡º0-1çš„å¥–åŠ±
        )

    def forward(self, state_features: torch.Tensor, goal_features: torch.Tensor) -> torch.Tensor:
        """
        Args:
            state_features: çŠ¶æ€ç‰¹å¾ (B, state_dim)
            goal_features: ç›®æ ‡ç‰¹å¾ (B, goal_dim)
        Returns:
            intrinsic_reward: å†…åœ¨å¥–åŠ± (B, 1)
        """
        combined = torch.cat([state_features, goal_features], dim=-1)
        return self.reward_network(combined)


# åˆ†å±‚Transformerå±‚
class HierarchicalTransformerLayer(nn.Module):
    """åˆ†å±‚Transformerå±‚ï¼Œæ”¯æŒç›®æ ‡æ¡ä»¶çš„æ³¨æ„åŠ›
    æŸ¥è¯¢ï¼ˆQueryï¼‰æ¥è‡ªç›®æ ‡-åŠ¨ä½œèåˆç‰¹å¾ï¼ŒæŠŠé«˜å±‚ç›®æ ‡å’Œä½å±‚åŠ¨ä½œçš„ä¿¡æ¯ç»“åˆåœ¨ä¸€èµ·å½¢æˆå‘é‡
    é”®ï¼ˆKeyï¼‰å’Œå€¼ï¼ˆValueï¼‰æ¥è‡ªè§†è§‰ç‰¹å¾"""

    def __init__(self, d_model=256, n_heads=8, d_ff=1024, dropout=0.1):
        super().__init__()
        assert d_model % n_heads == 0

        self.d_model = d_model
        self.n_heads = n_heads
        self.head_dim = d_model // n_heads
        self.scale = 1.0 / math.sqrt(self.head_dim)

        # Multi-head attention projections
        self.q_proj = nn.Linear(d_model, d_model, bias=False)
        self.k_proj = nn.Linear(d_model, d_model, bias=False)
        self.v_proj = nn.Linear(d_model, d_model, bias=False)
        self.out_proj = nn.Linear(d_model, d_model)

        # Goal-conditioned attention
        self.goal_q_proj = nn.Linear(d_model, d_model, bias=False)

        # Feed forward network
        self.ffn = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_ff, d_model)
        )

        # Layer normalization
        self.ln1 = nn.LayerNorm(d_model)
        self.ln2 = nn.LayerNorm(d_model)

        # Dropout
        self.attn_dropout = nn.Dropout(dropout)
        self.ffn_dropout = nn.Dropout(dropout)

    def forward(self, x, goal_action_features):
        """
        Args:
            x: è§†è§‰ç‰¹å¾ (B, d_model)
            goal_action_features: ç›®æ ‡-åŠ¨ä½œèåˆç‰¹å¾ (B, d_model)
        """
        B = x.size(0)

        # 1. Goal-conditioned multi-head attention
        residual = x
        x_norm = self.ln1(x)
        goal_norm = self.ln1(goal_action_features)

        # ç›®æ ‡ä½œä¸ºquery, è§†è§‰ç‰¹å¾ä½œä¸ºkeyå’Œvalue
        Q = self.goal_q_proj(goal_norm).view(B, self.n_heads, self.head_dim)
        K = self.k_proj(x_norm).view(B, self.n_heads, self.head_dim)
        V = self.v_proj(x_norm).view(B, self.n_heads, self.head_dim)

        # æ³¨æ„åŠ›è®¡ç®—
        scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale
        attn_weights = F.softmax(scores, dim=-1)
        attn_weights = self.attn_dropout(attn_weights)

        attended = torch.matmul(attn_weights, V)
        attended = attended.view(B, self.d_model)
        attended = self.out_proj(attended)
        x = residual + attended

        # 2. Feed forward with residual connection
        residual = x
        x_norm = self.ln2(x)
        x = residual + self.ffn_dropout(self.ffn(x_norm))

        return x


# åˆ†å±‚é¢„æµ‹æ¨¡å‹
class HierarchicalPredictiveModel(nn.Module):
    """åˆ†å±‚é¢„æµ‹æ¨¡å‹ - é›†æˆç›®æ ‡ä¿¡æ¯"""

    def __init__(self, d_model=256, goal_dim=256, action_dim=19, n_heads=8, n_layers=3, d_ff=1024, dropout=0.1):
        super().__init__()

        # åŠ¨ä½œç¼–ç å™¨
        self.action_encoder = ActionEncoder(action_dim=action_dim, output_dim=d_model)

        # ç›®æ ‡-åŠ¨ä½œèåˆå±‚
        self.goal_action_fusion = nn.Sequential(
            nn.Linear(d_model + goal_dim, d_model),
            nn.LayerNorm(d_model),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # Transformerå±‚
        self.layers = nn.ModuleList([
            HierarchicalTransformerLayer(d_model, n_heads, d_ff, dropout)
            for _ in range(n_layers)
        ])

        # è¾“å‡ºå±‚å½’ä¸€åŒ–
        self.output_ln = nn.LayerNorm(d_model)

    def forward(self, state_features, actions, goal_features):
        """
        Args:
            state_features: ç¼–ç å™¨è¾“å‡º (B, d_model)
            actions: åŠ¨ä½œç´¢å¼• (B,)
            goal_features: ç›®æ ‡ç‰¹å¾ (B, goal_dim)
        Returns:
            predicted_features: é¢„æµ‹ç‰¹å¾ (B, d_model)
        """
        # ç¼–ç åŠ¨ä½œ
        action_features = self.action_encoder(actions)

        # èåˆç›®æ ‡å’ŒåŠ¨ä½œä¿¡æ¯
        goal_action_combined = torch.cat([action_features, goal_features], dim=-1)
        goal_action_features = self.goal_action_fusion(goal_action_combined)

        # é€šè¿‡Transformerå±‚
        x = state_features
        for layer in self.layers:
            x = layer(x, goal_action_features)

        # è¾“å‡ºå½’ä¸€åŒ–
        x = self.output_ln(x)

        return x


# ============================================================================
# ä¸»æ¨¡å‹ï¼šåˆ†å±‚PRM_JE
# ============================================================================

class HierarchicalPRM_JE(nn.Module):
    """åˆ†å±‚é¢„æµ‹è¡¨ç¤ºæ¨¡å‹ - é›†æˆå…ƒæ§åˆ¶å™¨å’Œæ§åˆ¶å™¨"""

    def __init__(
            self,
            img_in_channels: int = 3,
            encoder_layers: List[int] = [2, 3, 4, 3],
            action_dim: int = 19,
            latent_dim: int = 256,
            base_channels: int = 64,
            num_attention_heads: int = 8,
            transformer_layers: int = 3,
            loss_weight: float = 1.0,
            dropout: float = 0.1,
            # æ–°å¢ï¼šåˆ†å±‚å‚æ•°
            goal_dim: int = 64,
            num_goal_types: int = 3,
            meta_hidden_dim: int = 512
    ) -> None:
        super().__init__()

        # åŸæœ‰ç¼–ç å™¨
        self.encoder = Encoder(img_in_channels, encoder_layers, base_channels)

        # === æ–°å¢ï¼šåˆ†å±‚ç»„ä»¶ ===
        # 1. ç›®æ ‡ç¼–ç å™¨
        self.goal_encoder = GoalEncoder(goal_dim, latent_dim)

        # 2. å…ƒæ§åˆ¶å™¨
        self.meta_controller = MetaController(latent_dim, meta_hidden_dim, num_goal_types)

        # 3. åˆ†å±‚é¢„æµ‹æ¨¡å‹ï¼ˆæ›¿æ¢åŸæœ‰çš„predictive_modelï¼‰
        self.predictive_model = HierarchicalPredictiveModel(
            d_model=latent_dim,
            goal_dim=latent_dim,  # ç›®æ ‡ç¼–ç åçš„ç»´åº¦
            action_dim=action_dim,
            n_heads=num_attention_heads,
            n_layers=transformer_layers,
            dropout=dropout
        )

        # 4. å†…åœ¨å¥–åŠ±è®¡ç®—å™¨
        self.intrinsic_critic = IntrinsicCritic(latent_dim, latent_dim)

        # å…¶ä»–å‚æ•°
        self.loss_weight = loss_weight
        self.goal_types = ['spatial', 'object', 'exploration']

        # åˆ†å±‚çŠ¶æ€è·Ÿè¸ª
        self.current_goal_type = None
        self.current_goal_params = None
        self.goal_step_count = 0
        self.goal_selection_interval = 5

        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)

    def _init_weights(self, m):
        """å‚è€ƒLLMçš„æƒé‡åˆå§‹åŒ–ç­–ç•¥"""
        if isinstance(m, nn.Linear):
            nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.Embedding):
            nn.init.normal_(m.weight, mean=0, std=0.02)
        elif isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
            nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, (nn.BatchNorm2d, nn.LayerNorm)):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)

    def select_goal(self, state_features: torch.Tensor, epsilon: float = 0.1) -> Tuple[str, torch.Tensor]:
        """
        é€‰æ‹©ç›®æ ‡ï¼ˆepsilon-greedyç­–ç•¥ï¼‰
        Args:
            state_features: çŠ¶æ€ç‰¹å¾ (B, latent_dim)
            epsilon: æ¢ç´¢æ¦‚ç‡
        Returns:
            goal_type: é€‰æ‹©çš„ç›®æ ‡ç±»å‹
            goal_params: ç›®æ ‡å‚æ•°
        """
        if np.random.random() < epsilon:
            # éšæœºé€‰æ‹©ç›®æ ‡
            goal_type = np.random.choice(self.goal_types)
        else:
            # åŸºäºQå€¼é€‰æ‹©ç›®æ ‡
            with torch.no_grad():
                goal_q_values, _ = self.meta_controller(state_features)
                goal_idx = torch.argmax(goal_q_values, dim=1)[0].item()
                goal_type = self.goal_types[goal_idx]

        # ç”Ÿæˆç›®æ ‡å‚æ•°
        with torch.no_grad():
            _, goal_params = self.meta_controller(state_features, goal_type)

        return goal_type, goal_params

    def forward(self, images: torch.Tensor, actions: torch.Tensor,
                goal_type: str = None, goal_params: torch.Tensor = None) -> Tuple[
        torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        Args:
            images: è¾“å…¥å›¾åƒ (B, 3, 210, 160)
            actions: åŠ¨ä½œ (B,) - 0åˆ°18çš„æ•´æ•°
            goal_type: ç›®æ ‡ç±»å‹
            goal_params: ç›®æ ‡å‚æ•°
        Returns:
            encoder_features: ç¼–ç å™¨è¾“å‡º (B, 256)
            predicted_features: é¢„æµ‹æ¨¡å‹è¾“å‡º (B, 256)
            goal_features: ç›®æ ‡ç‰¹å¾ (B, 256)
        """
        # ç¡®ä¿åŠ¨ä½œåœ¨æ­£ç¡®èŒƒå›´å†…
        assert actions.min() >= 0 and actions.max() <= 18, f"Actions must be in range [0, 18]"

        # ç¼–ç 
        encoder_features = self.encoder(images)

        # ç›®æ ‡å¤„ç†
        if goal_type is None or goal_params is None:
            # è‡ªåŠ¨é€‰æ‹©ç›®æ ‡
            goal_type, goal_params = self.select_goal(encoder_features)

        # ç¼–ç ç›®æ ‡
        goal_features = self.goal_encoder(goal_type, goal_params)

        # åˆ†å±‚é¢„æµ‹
        predicted_features = self.predictive_model(encoder_features, actions, goal_features)

        return encoder_features, predicted_features, goal_features

    def compute_controller_loss(self, predicted_features: torch.Tensor, target_features: torch.Tensor,
                                current_features: torch.Tensor, goal_features: torch.Tensor) -> Tuple[
        torch.Tensor, dict]:
        """
        è®¡ç®—æ§åˆ¶å™¨æŸå¤±ï¼ˆé¢„æµ‹æŸå¤± + å†…åœ¨å¥–åŠ±æŸå¤±ï¼‰
        """
        # 1. é¢„æµ‹æŸå¤±ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        pred_norm = F.normalize(predicted_features, p=2, dim=1)
        target_norm = F.normalize(target_features, p=2, dim=1)
        cosine_sim = (pred_norm * target_norm).sum(dim=1)
        prediction_loss = (1.0 - cosine_sim).mean()

        # 2. å†…åœ¨å¥–åŠ±æŸå¤±
        intrinsic_reward = self.intrinsic_critic(target_features, goal_features)
        # é¼“åŠ±é«˜å†…åœ¨å¥–åŠ±ï¼ˆç›®æ ‡å¯¼å‘ï¼‰
        intrinsic_loss = F.mse_loss(intrinsic_reward, torch.ones_like(intrinsic_reward))

        # æ€»æ§åˆ¶å™¨æŸå¤±
        total_loss = self.loss_weight * prediction_loss + 0.1 * intrinsic_loss

        loss_dict = {
            'controller_total_loss': total_loss.item(),
            'prediction_loss': prediction_loss.item(),
            'intrinsic_loss': intrinsic_loss.item(),
            'cosine_similarity': cosine_sim.mean().item(),
            'intrinsic_reward': intrinsic_reward.mean().item()
        }

        return total_loss, loss_dict

    def compute_meta_loss(self, transitions: List[Dict]) -> Tuple[torch.Tensor, dict]:
        """
        è®¡ç®—å…ƒæ§åˆ¶å™¨æŸå¤±ï¼ˆåŸºäºç´¯ç§¯å¤–åœ¨å¥–åŠ±çš„Q-learningï¼‰
        """
        if not transitions:
            device = next(self.parameters()).device
            return torch.tensor(0.0, device=device), {}

        total_loss = 0
        count = 0

        for trans in transitions:
            state_features = trans['state_features']
            goal_type_idx = self.goal_types.index(trans['goal_type'])
            extrinsic_reward = trans['extrinsic_reward']
            next_state_features = trans['next_state_features']
            done = trans['done']

            # å½“å‰Qå€¼
            current_q_values, _ = self.meta_controller(state_features)
            current_q = current_q_values[0, goal_type_idx]

            # ç›®æ ‡Qå€¼
            with torch.no_grad():
                if done:
                    target_q = extrinsic_reward
                else:
                    next_q_values, _ = self.meta_controller(next_state_features)
                    target_q = extrinsic_reward + 0.99 * torch.max(next_q_values)

            loss = F.mse_loss(current_q, target_q)
            total_loss += loss
            count += 1

        avg_loss = total_loss / count if count > 0 else total_loss

        loss_dict = {
            'meta_loss': avg_loss.item(),
            'num_transitions': count
        }

        return avg_loss, loss_dict


# ============================================================================
# æ¨¡å‹åˆ†æå·¥å…·ï¼ˆç°åœ¨å¯ä»¥å®‰å…¨å¼•ç”¨HierarchicalPRM_JEï¼‰
# ============================================================================

class HierarchicalModelAnalyzer:
    """åˆ†å±‚æ¨¡å‹åˆ†æå·¥å…·"""

    def __init__(self, model: HierarchicalPRM_JE):
        self.model = model

    def analyze_goal_distribution(self, images: torch.Tensor, num_samples: int = 100):
        """åˆ†æç›®æ ‡åˆ†å¸ƒ"""
        goal_counts = {goal_type: 0 for goal_type in self.model.goal_types}

        with torch.no_grad():
            # å…ˆç¼–ç å›¾åƒä¸ºç‰¹å¾
            state_features = self.model.encoder(images[:1])

            for _ in range(num_samples):
                goal_type, _ = self.model.select_goal(state_features, epsilon=0.0)
                goal_counts[goal_type] += 1

        return {k: v / num_samples for k, v in goal_counts.items()}

    def get_goal_q_values(self, images: torch.Tensor):
        """è·å–ç›®æ ‡Qå€¼"""
        with torch.no_grad():
            # ç¼–ç å›¾åƒä¸ºç‰¹å¾
            features = self.model.encoder(images)
            q_values, _ = self.model.meta_controller(features)
            return q_values

    def compute_intrinsic_reward_statistics(self, images: torch.Tensor, goal_type: str):
        """è®¡ç®—å†…åœ¨å¥–åŠ±ç»Ÿè®¡"""
        with torch.no_grad():
            # ç¼–ç å›¾åƒä¸ºç‰¹å¾
            features = self.model.encoder(images)
            _, goal_params = self.model.meta_controller(features[:1], goal_type)
            goal_features = self.model.goal_encoder(goal_type, goal_params.expand(len(features), -1))
            intrinsic_rewards = self.model.intrinsic_critic(features, goal_features)

            return {
                'mean': intrinsic_rewards.mean().item(),
                'std': intrinsic_rewards.std().item(),
                'min': intrinsic_rewards.min().item(),
                'max': intrinsic_rewards.max().item()
            }


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def create_hierarchical_optimizers(model, controller_lr=1e-4, meta_lr=1e-5, weight_decay=1e-2):
    """åˆ›å»ºåˆ†å±‚ä¼˜åŒ–å™¨"""

    # æ§åˆ¶å™¨å‚æ•°ï¼ˆç¼–ç å™¨ + é¢„æµ‹æ¨¡å‹ + å†…åœ¨å¥–åŠ±ï¼‰
    controller_params = list(model.encoder.parameters()) + \
                        list(model.predictive_model.parameters()) + \
                        list(model.intrinsic_critic.parameters()) + \
                        list(model.goal_encoder.parameters())

    # å…ƒæ§åˆ¶å™¨å‚æ•°
    meta_params = list(model.meta_controller.parameters())

    # åˆ†åˆ«åˆ›å»ºä¼˜åŒ–å™¨
    controller_optimizer = torch.optim.AdamW(
        controller_params,
        lr=controller_lr,
        betas=(0.9, 0.95),
        eps=1e-8,
        weight_decay=weight_decay
    )

    meta_optimizer = torch.optim.AdamW(
        meta_params,
        lr=meta_lr,
        betas=(0.9, 0.95),
        eps=1e-8,
        weight_decay=weight_decay
    )

    return controller_optimizer, meta_optimizer


def create_hierarchical_lr_schedulers(controller_optimizer, meta_optimizer,
                                      controller_warmup_steps=1000, meta_warmup_steps=500,
                                      controller_max_steps=10000, meta_max_steps=5000):
    """åˆ›å»ºåˆ†å±‚å­¦ä¹ ç‡è°ƒåº¦å™¨"""

    def controller_lr_lambda(step):
        if step < controller_warmup_steps:
            return step / controller_warmup_steps
        else:
            progress = (step - controller_warmup_steps) / (controller_max_steps - controller_warmup_steps)
            progress = min(progress, 1.0)
            return 0.1 + 0.9 * (0.5 * (1 + math.cos(math.pi * progress)))

    def meta_lr_lambda(step):
        if step < meta_warmup_steps:
            return step / meta_warmup_steps
        else:
            progress = (step - meta_warmup_steps) / (meta_max_steps - meta_warmup_steps)
            progress = min(progress, 1.0)
            return 0.1 + 0.9 * (0.5 * (1 + math.cos(math.pi * progress)))

    controller_scheduler = torch.optim.lr_scheduler.LambdaLR(controller_optimizer, controller_lr_lambda)
    meta_scheduler = torch.optim.lr_scheduler.LambdaLR(meta_optimizer, meta_lr_lambda)

    return controller_scheduler, meta_scheduler


# ============================================================================
# å…¼å®¹æ€§å‡½æ•° - ä¿æŒä¸åŸæœ‰ä»£ç çš„å…¼å®¹æ€§
# ============================================================================

def create_optimized_optimizer(model, base_lr=1e-4, weight_decay=1e-2):
    """
    å…¼å®¹åŸæœ‰ä»£ç çš„ä¼˜åŒ–å™¨åˆ›å»ºå‡½æ•°
    å¯¹äºåˆ†å±‚æ¨¡å‹ï¼Œè¿™ä¸ªå‡½æ•°åªåˆ›å»ºæ§åˆ¶å™¨ä¼˜åŒ–å™¨
    """
    if isinstance(model, HierarchicalPRM_JE):
        # å¦‚æœæ˜¯åˆ†å±‚æ¨¡å‹ï¼Œåªè¿”å›æ§åˆ¶å™¨ä¼˜åŒ–å™¨
        controller_optimizer, _ = create_hierarchical_optimizers(
            model, controller_lr=base_lr, meta_lr=base_lr * 0.1, weight_decay=weight_decay
        )
        return controller_optimizer
    else:
        # åŸæœ‰çš„ä¼˜åŒ–å™¨é€»è¾‘ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        decay_params = []
        no_decay_params = []

        for name, param in model.named_parameters():
            if not param.requires_grad:
                continue
            if len(param.shape) <= 1 or name.endswith(".bias") or "norm" in name.lower():
                no_decay_params.append(param)
            else:
                decay_params.append(param)

        optimizer_grouped_parameters = [
            {
                "params": decay_params,
                "weight_decay": weight_decay,
                "lr": base_lr
            },
            {
                "params": no_decay_params,
                "weight_decay": 0.0,
                "lr": base_lr
            }
        ]

        optimizer = torch.optim.AdamW(
            optimizer_grouped_parameters,
            lr=base_lr,
            betas=(0.9, 0.95),
            eps=1e-8,
            weight_decay=weight_decay
        )

        return optimizer


def create_lr_scheduler(optimizer, warmup_steps=1000, max_steps=10000, min_lr_ratio=0.1):
    """
    å…¼å®¹åŸæœ‰ä»£ç çš„å­¦ä¹ ç‡è°ƒåº¦å™¨åˆ›å»ºå‡½æ•°
    """

    def lr_lambda(step):
        if step < warmup_steps:
            return step / warmup_steps
        else:
            progress = (step - warmup_steps) / (max_steps - warmup_steps)
            progress = min(progress, 1.0)
            cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))
            return min_lr_ratio + (1 - min_lr_ratio) * cosine_decay

    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
    return scheduler


# ============================================================================
# å·¥å‚å‡½æ•° - æ ¹æ®é…ç½®åˆ›å»ºåˆé€‚çš„æ¨¡å‹
# ============================================================================

def create_prm_model(model_type='hierarchical', **kwargs):
    """
    å·¥å‚å‡½æ•°ï¼šæ ¹æ®ç±»å‹åˆ›å»ºåˆé€‚çš„PRMæ¨¡å‹
    Args:
        model_type: æ¨¡å‹ç±»å‹ ('hierarchical' æˆ– 'original')
        **kwargs: æ¨¡å‹å‚æ•°
    """
    if model_type == 'hierarchical':
        return HierarchicalPRM_JE(**kwargs)
    else:
        # è¿™é‡Œå¯ä»¥æ·»åŠ åŸæœ‰PRM_JEçš„å¯¼å…¥å’Œåˆ›å»ºé€»è¾‘
        raise NotImplementedError("Original PRM_JE not implemented in this file")


# ============================================================================
# æµ‹è¯•å’Œæ¼”ç¤ºä»£ç 
# ============================================================================

if __name__ == '__main__':
    # === æµ‹è¯•åˆ†å±‚æ¨¡å‹ ===
    print("=== Hierarchical PRM_JE Model Testing ===")

    BATCH_SIZE = 4
    IMG_C = 3
    IMG_H = 210
    IMG_W = 160
    ACTION_DIM = 19

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dummy_images = torch.rand(BATCH_SIZE, IMG_C, IMG_H, IMG_W)
    dummy_actions = torch.randint(0, ACTION_DIM, (BATCH_SIZE,))
    dummy_next_images = torch.rand(BATCH_SIZE, IMG_C, IMG_H, IMG_W)

    # åˆ›å»ºåˆ†å±‚æ¨¡å‹
    model = HierarchicalPRM_JE(
        img_in_channels=IMG_C,
        encoder_layers=[2, 3, 4, 3],
        action_dim=ACTION_DIM,
        latent_dim=256,
        base_channels=64,
        num_attention_heads=8,
        transformer_layers=3,
        loss_weight=1.0,
        dropout=0.1,
        goal_dim=64,
        num_goal_types=3,
        meta_hidden_dim=512
    )

    # å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    controller_params = sum(p.numel() for p in
                            list(model.encoder.parameters()) +
                            list(model.predictive_model.parameters()) +
                            list(model.intrinsic_critic.parameters()) +
                            list(model.goal_encoder.parameters()))
    meta_params = sum(p.numel() for p in model.meta_controller.parameters())

    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"æ§åˆ¶å™¨å‚æ•°: {controller_params:,}")
    print(f"å…ƒæ§åˆ¶å™¨å‚æ•°: {meta_params:,}")

    # æµ‹è¯•å‰å‘ä¼ æ’­
    print(f"\n=== å‰å‘ä¼ æ’­æµ‹è¯• ===")
    model.eval()
    with torch.no_grad():
        encoder_features, predicted_features, goal_features = model(dummy_images, dummy_actions)
        print(f"âœ… ç¼–ç å™¨ç‰¹å¾: {encoder_features.shape}")
        print(f"âœ… é¢„æµ‹ç‰¹å¾: {predicted_features.shape}")
        print(f"âœ… ç›®æ ‡ç‰¹å¾: {goal_features.shape}")

    # åˆ›å»ºåˆ†å±‚ä¼˜åŒ–å™¨
    controller_optimizer, meta_optimizer = create_hierarchical_optimizers(model)
    controller_scheduler, meta_scheduler = create_hierarchical_lr_schedulers(
        controller_optimizer, meta_optimizer
    )

    print(f"\n=== åˆ†å±‚è®­ç»ƒæµ‹è¯• ===")
    n_epochs = 20

    for epoch in range(n_epochs):
        model.train()

        # === æ§åˆ¶å™¨è®­ç»ƒæ­¥éª¤ ===
        controller_optimizer.zero_grad()

        # å‰å‘ä¼ æ’­
        encoder_features, predicted_features, goal_features = model(dummy_images, dummy_actions)

        # ç›®æ ‡ç‰¹å¾
        with torch.no_grad():
            target_features = model.encoder(dummy_next_images)

        # è®¡ç®—æ§åˆ¶å™¨æŸå¤±
        controller_loss, controller_loss_dict = model.compute_controller_loss(
            predicted_features, target_features, encoder_features, goal_features
        )

        # æ§åˆ¶å™¨åå‘ä¼ æ’­
        controller_loss.backward()
        torch.nn.utils.clip_grad_norm_(
            list(model.encoder.parameters()) +
            list(model.predictive_model.parameters()) +
            list(model.intrinsic_critic.parameters()) +
            list(model.goal_encoder.parameters()),
            max_norm=1.0
        )
        controller_optimizer.step()
        controller_scheduler.step()

        # === å…ƒæ§åˆ¶å™¨è®­ç»ƒæ­¥éª¤ï¼ˆåˆ†ç¦»è®¡ç®—å›¾ï¼‰===
        if epoch % 5 == 0:  # æ¯5æ­¥æ›´æ–°å…ƒæ§åˆ¶å™¨
            meta_optimizer.zero_grad()

            # é‡æ–°ç¼–ç ç‰¹å¾ï¼ˆé¿å…è®¡ç®—å›¾å†²çªï¼‰
            with torch.no_grad():
                meta_state_features = model.encoder(dummy_images[0:1])
                meta_next_features = model.encoder(dummy_next_images[0:1])

            meta_transitions = [{
                'state_features': meta_state_features,
                'goal_type': 'spatial',
                'extrinsic_reward': torch.tensor(0.1),
                'next_state_features': meta_next_features,
                'done': False
            }]

            meta_loss, meta_loss_dict = model.compute_meta_loss(meta_transitions)

            if meta_loss.item() > 0:
                meta_loss.backward()
                torch.nn.utils.clip_grad_norm_(model.meta_controller.parameters(), max_norm=1.0)
                meta_optimizer.step()
                meta_scheduler.step()

        if (epoch + 1) % 5 == 0:
            controller_lr = controller_optimizer.param_groups[0]['lr']
            meta_lr = meta_optimizer.param_groups[0]['lr']
            print(f'Epoch {epoch + 1:3d}/{n_epochs}, '
                  f'Controller Loss: {controller_loss_dict["controller_total_loss"]:.6f}, '
                  f'Prediction: {controller_loss_dict["prediction_loss"]:.6f}, '
                  f'Intrinsic: {controller_loss_dict["intrinsic_loss"]:.6f}, '
                  f'C_LR: {controller_lr:.2e}, M_LR: {meta_lr:.2e}')

    # æµ‹è¯•æ¨¡å‹åˆ†æå™¨
    print(f"\n=== æ¨¡å‹åˆ†ææµ‹è¯• ===")
    analyzer = HierarchicalModelAnalyzer(model)

    # åˆ†æç›®æ ‡åˆ†å¸ƒï¼ˆä½¿ç”¨è¾ƒå°‘æ ·æœ¬ä»¥åŠ å¿«æµ‹è¯•ï¼‰
    goal_distribution = analyzer.analyze_goal_distribution(dummy_images, num_samples=50)
    print(f"ç›®æ ‡åˆ†å¸ƒ: {goal_distribution}")

    # è·å–Qå€¼
    q_values = analyzer.get_goal_q_values(dummy_images)
    print(f"ç›®æ ‡Qå€¼å½¢çŠ¶: {q_values.shape}")
    print(f"ç›®æ ‡Qå€¼: {q_values[0].tolist()}")

    # è®¡ç®—å†…åœ¨å¥–åŠ±ç»Ÿè®¡
    for goal_type in model.goal_types:
        stats = analyzer.compute_intrinsic_reward_statistics(dummy_images, goal_type)
        print(f"{goal_type}ç›®æ ‡å†…åœ¨å¥–åŠ±ç»Ÿè®¡: {stats}")

    print(f"\n=== åˆ†å±‚PRM_JEæ¨¡å‹æ€»ç»“ ===")
    print(f"âœ… ç¼–ç å™¨: å¤„ç†210Ã—160Ã—3å›¾åƒ â†’ 256ç»´ç‰¹å¾")
    print(f"âœ… ç›®æ ‡ç¼–ç å™¨: æ”¯æŒç©ºé—´ã€å¯¹è±¡ã€æ¢ç´¢ä¸‰ç§ç›®æ ‡ç±»å‹")
    print(f"âœ… å…ƒæ§åˆ¶å™¨: åŸºäºçŠ¶æ€é€‰æ‹©ç›®æ ‡ç±»å‹å’Œå‚æ•°")
    print(f"âœ… åˆ†å±‚é¢„æµ‹: ç»“åˆç›®æ ‡ä¿¡æ¯çš„Transformeré¢„æµ‹")
    print(f"âœ… å†…åœ¨å¥–åŠ±: è¯„ä¼°ç›®æ ‡å®Œæˆæƒ…å†µ")
    print(f"âœ… åŒå±‚ä¼˜åŒ–: æ§åˆ¶å™¨å’Œå…ƒæ§åˆ¶å™¨åˆ†åˆ«ä¼˜åŒ–")
    print(f"âœ… æ¨¡å‹åˆ†æ: æ”¯æŒç›®æ ‡åˆ†å¸ƒå’Œå¥–åŠ±ç»Ÿè®¡åˆ†æ")
    print(f"âœ… æ€»å‚æ•°: {total_params:,}")
    print("ğŸ‰ åˆ†å±‚PRM_JEæ¨¡å‹æµ‹è¯•å®Œæˆï¼")
